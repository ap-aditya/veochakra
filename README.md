
# ğŸ¯ AI Surveillance Anomaly Detection Dashboard

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-red)](https://streamlit.io)
[![YOLOv8](https://img.shields.io/badge/YOLOv8-Object%20Detection-green)](https://github.com/ultralytics/ultralytics)
[![LightGBM](https://img.shields.io/badge/LightGBM-ML%20Scoring-orange)](https://lightgbm.readthedocs.io)

A comprehensive real-time anomaly detection system for video surveillance using state-of-the-art machine learning models. The dashboard combines **YOLOv8** object detection, **DeepSORT** tracking, and **LightGBM** classification to identify anomalous behavior in video streams with an intuitive web interface.

## ğŸŒŸ Features

### ğŸ” **Advanced Detection Pipeline**
- **YOLOv8 Object Detection**: High-accuracy object detection with customizable classes
- **DeepSORT Tracking**: Persistent object tracking with unique IDs across frames
- **LightGBM Scoring**: Machine learning-based anomaly classification
- **Real-time Processing**: Configurable FPS processing for optimal performance

### ğŸ“Š **Interactive Dashboard**
- **Live Video Display**: Real-time video playback with detection overlays
- **Anomaly Score Visualization**: Dynamic plotting with threshold indicators
- **Event Detection**: Automatic anomaly event identification with hysteresis
- **Screenshot Capture**: Automatic screenshot saving during anomaly events

### ğŸ’¾ **Intelligent Caching System**
- **Replay Mode**: Instant replay using cached detections (no reprocessing)
- **Live Detection Mode**: Real-time analysis with automatic cache generation
- **Cache Management**: Built-in tools for cleaning and managing detection caches

### ğŸ“ˆ **Comprehensive Reporting**
- **Per-frame Analysis**: Detailed CSV with scores and engineered features
- **Event Summaries**: Complete event logs with timestamps and durations
- **Screenshot Archives**: Organized image collections of detected anomalies
- **Complete Report Downloads**: Single-click download of all analysis data

### ğŸ”„ **Multi-page Interface**
- **Main Dashboard**: Primary analysis and processing interface
- **Replay Page**: Browse and review historical analysis results
- **Auto-cleanup**: Configurable automatic cleanup of old files and caches

## ï¿½ **Docker Deployment**

The application is fully dockerized for easy deployment and consistent environments.

### **Quick Start with Docker**

```bash
# 1. Build and start the application
docker compose up -d

# 2. Access the dashboard
# URL: http://localhost:8501

# 3. View logs
docker compose logs -f

# 4. Stop the application
docker compose down
```

### **Docker Requirements**
- **Docker & Docker Compose**: Must be installed
- **Port 8501**: Must be available on host
- **Model Files**: Place in `artifacts/` directory:
  - `artifacts/lgbm_frame_scorer.joblib`
  - `artifacts/meta.json`

### **Persistent Data**
- **Uploads**: `./data/uploads` (mounted as volume)
- **Reports**: `./data/reports` (mounted as volume) 
- **Artifacts**: `./artifacts` (mounted as volume)

---

## ï¿½ğŸš€ Quick Start

### Prerequisites
- **Python 3.11**
- **uv** (package and environment manager by Astral)
- **Trained Model Artifacts** (see [Model Setup](#-model-setup))

### Installation

```bash
# 1. Clone or create project directory
mkdir anomaly-dashboard && cd anomaly-dashboard

# 2. Initialize project
uv init

# 3. Create directory structure
mkdir -p app inference artifacts data/uploads data/reports artifacts/cache_dets

# 4. Install dependencies (from provided pyproject.toml)
uv sync
```

### Model Setup

Place your trained model files in the `artifacts/` directory:

```
artifacts/
â”œâ”€â”€ lgbm_frame_scorer.joblib    # Trained LightGBM model
â””â”€â”€ meta.json                   # Model metadata and configuration
```

**Required `meta.json` format:**
```json
{
  "threshold": 0.5,
  "feature_names": ["feature1", "feature2", ...],
  "model_version": "1.0",
  "training_date": "2025-08-24"
}
```

### Running the Application

```bash
# Start the dashboard
uv run streamlit run app/streamlit_app.py
```

ğŸŒ **Access the dashboard at:** http://localhost:8501

## ğŸ“– User Guide

### ğŸ® Dashboard Controls

#### **Sidebar Configuration**
- **ğŸ“ Artifacts Directory**: Path to model files (default: `artifacts`)
- **ğŸ”„ Processing Mode**: 
  - *Replay*: Use cached detections for instant analysis
  - *Live Detection*: Real-time processing with YOLO+DeepSORT
- **ğŸ¯ Anomaly Threshold**: Detection sensitivity (0.0 - 1.0)
- **ğŸ“Š Smoothing Window**: Frame averaging for score stabilization
- **âš¡ Processing FPS**: Frame rate limit for performance optimization
- **ğŸ–¼ï¸ Display Options**: Toggle tracking IDs and screenshot capture

#### **Video Processing Workflow**

1. **ğŸ“¤ Upload Video**: Drag & drop or browse for MP4/AVI files
2. **âš™ï¸ Configure Settings**: Adjust threshold, smoothing, and processing options
3. **â–¶ï¸ Start Processing**: Begin analysis with selected mode
4. **ğŸ‘€ Monitor Progress**: Watch live video feed with detection overlays
5. **ğŸ“Š Review Results**: Analyze real-time score charts and event detection
6. **ğŸ“‹ Generate Report**: Create comprehensive analysis report
7. **ğŸ’¾ Download Results**: Get complete analysis package

### ğŸ“Š Interface Layout

#### **Main Dashboard**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Sidebar     â”‚     Video Display        â”‚
â”‚   - Settings    â”‚   - Live Feed            â”‚
â”‚   - Controls    â”‚   - Bounding Boxes       â”‚
â”‚   - File Info   â”‚   - Track IDs            â”‚
â”‚                 â”‚                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Events       â”‚    Anomaly Score Chart   â”‚
â”‚   - Real-time   â”‚   - Timeline View        â”‚
â”‚   - Timestamps  â”‚   - Threshold Line       â”‚
â”‚   - Screenshots â”‚   - Live Updates         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Results & Downloads**
- **ğŸ“‹ Event Summary**: Complete list of detected anomalies
- **ğŸ“¸ Screenshot Gallery**: Full-size event screenshots
- **ğŸ“¦ Complete Report**: Single download with all analysis data

### ğŸ”„ Replay Mode

Access historical analysis through the **Replay** page:

1. Navigate to **"Replay Previous Runs"** in the page selector
2. Choose from available report directories
3. Review past analysis results with:
   - Interactive score timelines
   - Event summaries with screenshots
   - Complete historical data

## ğŸ› ï¸ Advanced Configuration

### Performance Optimization

#### **Memory Management**
- Reduce **Processing FPS** (8-10 for CPU systems)
- Enable **Auto-cleanup** to manage disk space
- Use **Replay mode** for repeated analysis

#### **Custom Detection Classes**
Modify `CLASSES_TO_DETECT` in `inference/pipeline.py` to focus on specific object types:
```python
CLASSES_TO_DETECT = [0, 2, 5, 7]  # person, car, bus, truck
```

### Model Customization

#### **Feature Engineering**
Update feature extraction in `inference/pipeline.py`:
```python
def extract_features(detections, frame_info):
    # Custom feature extraction logic
    return engineered_features
```

#### **Scoring Models**
Replace LightGBM with custom models by updating `ScorerAdapter` class.

## ğŸ“ Project Structure

```
anomaly-dashboard/
â”œâ”€â”€ ğŸ“± app/
â”‚   â”œâ”€â”€ streamlit_app.py        # Main dashboard application
â”‚   â””â”€â”€ pages/
â”‚       â””â”€â”€ replay.py           # Historical analysis viewer
â”œâ”€â”€ ğŸ§  inference/
â”‚   â”œâ”€â”€ pipeline.py             # Core detection & scoring pipeline
â”‚   â”œâ”€â”€ cache_io.py             # JSONL cache management
â”‚   â”œâ”€â”€ events.py               # Event detection & reporting
â”‚   â””â”€â”€ draw.py                 # Video overlay rendering
â”œâ”€â”€ ğŸ¯ artifacts/
â”‚   â”œâ”€â”€ lgbm_frame_scorer.joblib # Trained anomaly detection model
â”‚   â”œâ”€â”€ meta.json               # Model configuration
â”‚   â””â”€â”€ cache_dets/             # Detection cache storage
â”œâ”€â”€ ğŸ’¾ data/
â”‚   â”œâ”€â”€ uploads/                # User-uploaded videos
â”‚   â””â”€â”€ reports/                # Generated analysis reports
â”œâ”€â”€ pyproject.toml              # Project dependencies
â”œâ”€â”€ uv.lock                     # Dependency lock file
â””â”€â”€ README.md                   # This documentation
```

## ğŸ”§ Troubleshooting

### Common Issues

#### **ğŸš« Model Not Found**
```
Error: Cannot load scorer from artifacts directory
```
**Solution**: Ensure `lgbm_frame_scorer.joblib` and `meta.json` exist in `artifacts/`

#### **âš¡ Performance Issues**
```
Video playback is slow or choppy
```
**Solutions**:
- Reduce Processing FPS to 8-10
- Enable person-only detection
- Use smaller video resolution
- Enable auto-cleanup for disk space

#### **ğŸ’¾ Cache Issues**
```
Replay mode not finding cached detections
```
**Solution**: Check `artifacts/cache_dets/` for matching `<video>_<size>.jsonl` files

#### **ğŸ“Š No Data in Charts**
```
Score chart appears empty
```
**Solutions**:
- Ensure video processing has started
- Check that threshold is set correctly
- Verify model artifacts are loaded

### Debug Mode

Enable verbose logging by setting environment variables:
```bash
export STREAMLIT_LOGGER_LEVEL=debug
uv run streamlit run app/streamlit_app.py
```

## ğŸ¤ Contributing

1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature-name`
3. **Commit** changes: `git commit -am 'Add feature'`
4. **Push** to branch: `git push origin feature-name`
5. **Submit** a Pull Request


## ğŸ™ Acknowledgments

- **[YOLOv8](https://github.com/ultralytics/ultralytics)** - Object detection framework
- **[DeepSORT](https://github.com/nwojke/deep_sort)** - Multi-object tracking
- **[LightGBM](https://lightgbm.readthedocs.io)** - Gradient boosting framework
- **[Streamlit](https://streamlit.io)** - Web application framework

---

**â­ Star this repository if you find it useful!**