{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:38.875549Z",
     "iopub.status.busy": "2025-08-24T17:05:38.874849Z",
     "iopub.status.idle": "2025-08-24T17:05:42.303928Z",
     "shell.execute_reply": "2025-08-24T17:05:42.302955Z",
     "shell.execute_reply.started": "2025-08-24T17:05:38.875516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.185)\n",
      "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.16)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas opencv-python torch scipy ultralytics deep-sort-realtime lightgbm scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:42.305866Z",
     "iopub.status.busy": "2025-08-24T17:05:42.305622Z",
     "iopub.status.idle": "2025-08-24T17:05:46.331336Z",
     "shell.execute_reply": "2025-08-24T17:05:46.330754Z",
     "shell.execute_reply.started": "2025-08-24T17:05:42.305843Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.332428Z",
     "iopub.status.busy": "2025-08-24T17:05:46.331998Z",
     "iopub.status.idle": "2025-08-24T17:05:46.369894Z",
     "shell.execute_reply": "2025-08-24T17:05:46.369343Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.332410Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_ROOT = Path(\"/kaggle/input/avenuedataset/Avenue Dataset\")\n",
    "    TRAIN_VIDEOS_PATH = DATA_ROOT / \"training_videos\"\n",
    "    TEST_VIDEOS_PATH = DATA_ROOT / \"testing_videos\"\n",
    "    GROUND_TRUTH_FOLDER_PATH = DATA_ROOT / \"testing_label_mask\"\n",
    "\n",
    "    YOLO_WEIGHTS = \"yolov8n.pt\"\n",
    "    CLASSES_TO_DETECT = [0, 24, 26, 28]  # person, backpack, handbag, suitcase\n",
    "    CONFIDENCE_THRESHOLD = 0.35\n",
    "    IOU_NMS = 0.5\n",
    "    DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # DeepSORT\n",
    "    MAX_AGE = 30\n",
    "    N_INIT = 3\n",
    "    MAX_DIST = 0.2\n",
    "    MAX_IOU_DISTANCE = 0.7\n",
    "    NN_BUDGET = 100\n",
    "\n",
    "    # Feature windows (seconds)\n",
    "    STATIONARY_WINDOW_SEC = 2.0\n",
    "    LOITER_WINDOW_SEC = 2.0\n",
    "    LOITERING_DIST_PX = 40.0\n",
    "    SPEED_THRESH_PX = 20.0\n",
    "    USE_TRAIN_NEGATIVES = True\n",
    "    NEGATIVE_RATIO = 10.0    \n",
    "    VAL_SLICE_MAX = 2000  \n",
    "    VALIDATION_ON_EVEN = True\n",
    "    RANDOM_SEED = 123\n",
    "\n",
    "    CACHE_DIR = Path(\"./cache_dets\")\n",
    "    ARTIFACT_DIR = Path(\"./artifacts_train\")\n",
    "\n",
    "def set_seeds(s=Config.RANDOM_SEED):\n",
    "    random.seed(s); np.random.seed(s); torch.manual_seed(s)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(s)\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.371938Z",
     "iopub.status.busy": "2025-08-24T17:05:46.371723Z",
     "iopub.status.idle": "2025-08-24T17:05:46.386067Z",
     "shell.execute_reply": "2025-08-24T17:05:46.385352Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.371921Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou_xyxy(a, b):\n",
    "    ax1, ay1, ax2, ay2 = a; bx1, by1, bx2, by2 = b\n",
    "    inter_x1, inter_y1 = max(ax1, bx1), max(ay1, by1)\n",
    "    inter_x2, inter_y2 = min(ax2, bx2), min(ay2, by2)\n",
    "    iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)\n",
    "    inter = iw * ih\n",
    "    area_a = max(0, ax2 - ax1) * max(0, ay2 - ay1)\n",
    "    area_b = max(0, bx2 - bx1) * max(0, by2 - by1)\n",
    "    union = area_a + area_b - inter + 1e-6\n",
    "    return inter / union if union > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.387108Z",
     "iopub.status.busy": "2025-08-24T17:05:46.386856Z",
     "iopub.status.idle": "2025-08-24T17:05:46.400751Z",
     "shell.execute_reply": "2025-08-24T17:05:46.400130Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.387092Z"
    }
   },
   "outputs": [],
   "source": [
    "def numeric_stem(path: Path):\n",
    "    s = path.stem\n",
    "    digits = \"\".join(ch for ch in s if ch.isdigit())\n",
    "    return int(digits) if digits else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.401733Z",
     "iopub.status.busy": "2025-08-24T17:05:46.401500Z",
     "iopub.status.idle": "2025-08-24T17:05:46.418556Z",
     "shell.execute_reply": "2025-08-24T17:05:46.417824Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.401684Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_stem_for_label(stem: str) -> str:\n",
    "    return str(int(stem)) if stem.isdigit() else stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.419923Z",
     "iopub.status.busy": "2025-08-24T17:05:46.419344Z",
     "iopub.status.idle": "2025-08-24T17:05:46.435022Z",
     "shell.execute_reply": "2025-08-24T17:05:46.434513Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.419896Z"
    }
   },
   "outputs": [],
   "source": [
    "def robust_load_gt(gt_path: Path):\n",
    "    try:\n",
    "        data = loadmat(str(gt_path), squeeze_me=True, struct_as_record=False)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR reading MAT {gt_path.name}: {e}\")\n",
    "        return None\n",
    "    for key in [\"volLabel\", \"label\", \"gt\", \"labels\"]:\n",
    "        if key not in data:\n",
    "            continue\n",
    "        arr = data[key]\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype != object:\n",
    "            flat = np.asarray(arr, dtype=np.float32).ravel()\n",
    "            return (flat > 0.5).astype(np.int32)\n",
    "        if isinstance(arr, (list, tuple)) or (isinstance(arr, np.ndarray) and arr.dtype == object):\n",
    "            vals = []\n",
    "            iterable = arr.ravel().tolist() if isinstance(arr, np.ndarray) else list(arr)\n",
    "            for elem in iterable:\n",
    "                if elem is None:\n",
    "                    vals.append(0.0)\n",
    "                else:\n",
    "                    e = np.asarray(elem, dtype=np.float32)\n",
    "                    vals.append(float(e.ravel()[0])) if e.size > 0 else vals.append(0.0)\n",
    "            if len(vals) > 0:\n",
    "                flat = np.asarray(vals, dtype=np.float32)\n",
    "                return (flat > 0.5).astype(np.int32)\n",
    "        try:\n",
    "            val = float(np.asarray(arr).ravel()[0])\n",
    "            return np.asarray([1 if val > 0.5 else 0], dtype=np.int32)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.435961Z",
     "iopub.status.busy": "2025-08-24T17:05:46.435761Z",
     "iopub.status.idle": "2025-08-24T17:05:46.451104Z",
     "shell.execute_reply": "2025-08-24T17:05:46.450426Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.435945Z"
    }
   },
   "outputs": [],
   "source": [
    "def cache_path_for(video_path: Path):\n",
    "    Config.CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    return Config.CACHE_DIR / f\"{video_path.stem}.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.452045Z",
     "iopub.status.busy": "2025-08-24T17:05:46.451829Z",
     "iopub.status.idle": "2025-08-24T17:05:46.465449Z",
     "shell.execute_reply": "2025-08-24T17:05:46.464814Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.452030Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_cache(video_path: Path, per_frame_dets):\n",
    "    with open(cache_path_for(video_path), \"w\") as f:\n",
    "        for dets in per_frame_dets:\n",
    "            f.write(json.dumps(dets) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.468715Z",
     "iopub.status.busy": "2025-08-24T17:05:46.468062Z",
     "iopub.status.idle": "2025-08-24T17:05:46.479027Z",
     "shell.execute_reply": "2025-08-24T17:05:46.478349Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.468695Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_cache(video_path: Path):\n",
    "    p = cache_path_for(video_path)\n",
    "    if not p.exists(): return None\n",
    "    with open(p, \"r\") as f:\n",
    "        return [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.479919Z",
     "iopub.status.busy": "2025-08-24T17:05:46.479654Z",
     "iopub.status.idle": "2025-08-24T17:05:46.495703Z",
     "shell.execute_reply": "2025-08-24T17:05:46.495119Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.479901Z"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_scores(scores, k=9):\n",
    "    k = max(1, int(k) | 1)\n",
    "    from collections import deque\n",
    "    out = np.zeros_like(scores)\n",
    "    q, s = deque(), 0.0\n",
    "    for i, v in enumerate(scores):\n",
    "        q.append(v); s += v\n",
    "        if len(q) > k:\n",
    "            s -= q.popleft()\n",
    "        out[i] = s / len(q)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.496625Z",
     "iopub.status.busy": "2025-08-24T17:05:46.496378Z",
     "iopub.status.idle": "2025-08-24T17:05:46.509932Z",
     "shell.execute_reply": "2025-08-24T17:05:46.509355Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.496590Z"
    }
   },
   "outputs": [],
   "source": [
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.model = YOLO(Config.YOLO_WEIGHTS)\n",
    "        self.model.fuse()\n",
    "        self.names = self.model.model.names\n",
    "\n",
    "    def detect(self, frame_bgr):\n",
    "        res = self.model.predict(\n",
    "            frame_bgr, conf=Config.CONFIDENCE_THRESHOLD, iou=Config.IOU_NMS,\n",
    "            device=Config.DEVICE, verbose=False\n",
    "        )[0]\n",
    "        dets = []\n",
    "        if res.boxes is None or len(res.boxes) == 0:\n",
    "            return dets, self.names\n",
    "        boxes = res.boxes.xyxy.cpu().numpy()\n",
    "        confs = res.boxes.conf.cpu().numpy()\n",
    "        clss = res.boxes.cls.cpu().numpy().astype(int)\n",
    "        for (x1, y1, x2, y2), c, k in zip(boxes, confs, clss):\n",
    "            if k in Config.CLASSES_TO_DETECT:\n",
    "                dets.append((float(x1), float(y1), float(x2), float(y2), float(c), int(k)))\n",
    "        return dets, self.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.511044Z",
     "iopub.status.busy": "2025-08-24T17:05:46.510733Z",
     "iopub.status.idle": "2025-08-24T17:05:46.526874Z",
     "shell.execute_reply": "2025-08-24T17:05:46.526166Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.511028Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self):\n",
    "        self.trk = DeepSort(\n",
    "            max_age=Config.MAX_AGE, n_init=Config.N_INIT,\n",
    "            max_iou_distance=Config.MAX_IOU_DISTANCE, max_cosine_distance=Config.MAX_DIST,\n",
    "            nn_budget=Config.NN_BUDGET, embedder=\"mobilenet\",\n",
    "            half=True if torch.cuda.is_available() else False, bgr=True\n",
    "        )\n",
    "\n",
    "    def update(self, frame_bgr, dets, class_names):\n",
    "        inputs = []\n",
    "        for (x1, y1, x2, y2, c, k) in dets:\n",
    "            w = max(0.0, x2 - x1)\n",
    "            h = max(0.0, y2 - y1)\n",
    "            inputs.append([(float(x1), float(y1), float(w), float(h)), float(c), str(class_names[k])])\n",
    "        tracks = self.trk.update_tracks(inputs, frame=frame_bgr)\n",
    "\n",
    "        det_boxes = [(float(x1), float(y1), float(x2), float(y2)) for (x1, y1, x2, y2, _, _) in dets]\n",
    "        det_classes = [int(k) for *_, k in dets]\n",
    "\n",
    "        out = []\n",
    "        for t in tracks:\n",
    "            if not t.is_confirmed(): continue\n",
    "            x1, y1, x2, y2 = t.to_tlbr()\n",
    "            cls_id = 0\n",
    "            if det_boxes:\n",
    "                ious = [iou_xyxy((x1, y1, x2, y2), b) for b in det_boxes]\n",
    "                j = int(np.argmax(ious))\n",
    "                if ious[j] > 0.3:\n",
    "                    cls_id = det_classes[j]\n",
    "            out.append({\n",
    "                \"box\": (float(x1), float(y1), float(x2), float(y2)),\n",
    "                \"id\": int(t.track_id),\n",
    "                \"center\": (float((x1+x2)/2), float((y1+y2)/2)),\n",
    "                \"cls_id\": int(cls_id)\n",
    "            })\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.527810Z",
     "iopub.status.busy": "2025-08-24T17:05:46.527573Z",
     "iopub.status.idle": "2025-08-24T17:05:46.541985Z",
     "shell.execute_reply": "2025-08-24T17:05:46.541357Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.527785Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATURE_ORDER = [\n",
    "    \"num_people\",\"num_objects\",\n",
    "    \"avg_speed_px\",\"max_speed_px\",\"avg_accel_px\",\n",
    "    \"fast_ratio\",\"loiter_ratio\",\"stationary_ratio\",\n",
    "    \"min_person_obj_px\",\"min_inter_person_px\",\"avg_inter_person_px\",\n",
    "    \"min_person_obj_norm\",\"min_inter_person_norm\",\"avg_inter_person_norm\",\n",
    "    \"mean_track_age\",\"median_track_age\",\"max_track_age\",\n",
    "    \"person_conf_mean\",\"person_conf_max\",\"object_conf_mean\",\"object_conf_max\",\n",
    "    \"grid_mean\",\"grid_max\",\"grid_std\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.543094Z",
     "iopub.status.busy": "2025-08-24T17:05:46.542839Z",
     "iopub.status.idle": "2025-08-24T17:05:46.731083Z",
     "shell.execute_reply": "2025-08-24T17:05:46.730327Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.543070Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureLogger:\n",
    "    def __init__(self, fps, w, h):\n",
    "        self.fps = float(fps) if fps and fps > 0 else 30.0\n",
    "        self.w, self.h = int(w), int(h)\n",
    "        self.img_diag = max(1.0, float(math.hypot(w, h)))\n",
    "        self.hist = defaultdict(lambda: deque(maxlen=int(self.fps * 10)))\n",
    "        self.first_seen = {}\n",
    "        self.frame_idx = 0\n",
    "        self.stationary_window = int(Config.STATIONARY_WINDOW_SEC * self.fps)\n",
    "        self.loiter_window = int(Config.LOITER_WINDOW_SEC * self.fps)\n",
    "        self.last_detections = []  # [(cls_id, conf)]\n",
    "\n",
    "    def set_last_detections(self, dets):\n",
    "        self.last_detections = [(int(k), float(c)) for (*_, c, k) in dets]\n",
    "\n",
    "    def step(self, tracked_objects):\n",
    "        self.frame_idx += 1\n",
    "        for obj in tracked_objects:\n",
    "            tid = obj[\"id\"]\n",
    "            self.hist[tid].append(obj[\"center\"])\n",
    "            if tid not in self.first_seen:\n",
    "                self.first_seen[tid] = self.frame_idx\n",
    "        return self._aggregate(tracked_objects)\n",
    "\n",
    "    def _aggregate(self, objs):\n",
    "        people = [o for o in objs if o[\"cls_id\"] == 0]\n",
    "        others = [o for o in objs if o[\"cls_id\"] != 0]\n",
    "\n",
    "        num_people, num_objects = len(people), len(others)\n",
    "\n",
    "        speeds, accels, loiter_flags, stationary_flags = [], [], [], []\n",
    "        for p in people:\n",
    "            tid = p[\"id\"]; h = self.hist[tid]\n",
    "            if len(h) >= 2:\n",
    "                s = float(np.linalg.norm(np.array(h[-1]) - np.array(h[-2])))\n",
    "                speeds.append(s)\n",
    "            if len(h) >= 3:\n",
    "                s1 = float(np.linalg.norm(np.array(h[-1]) - np.array(h[-2])))\n",
    "                s2 = float(np.linalg.norm(np.array(h[-2]) - np.array(h[-3])))\n",
    "                accels.append(abs(s1 - s2))\n",
    "            if len(h) >= self.loiter_window:\n",
    "                disp = float(np.linalg.norm(np.array(h[-1]) - np.array(h[-self.loiter_window])))\n",
    "                loiter_flags.append(1.0 if disp < Config.LOITERING_DIST_PX else 0.0)\n",
    "            if len(h) >= self.stationary_window:\n",
    "                disp = float(np.linalg.norm(np.array(h[-1]) - np.array(h[-self.stationary_window])))\n",
    "                stationary_flags.append(1.0 if disp < (0.6 * Config.LOITERING_DIST_PX) else 0.0)\n",
    "\n",
    "        avg_speed = float(np.mean(speeds)) if speeds else 0.0\n",
    "        max_speed = float(np.max(speeds)) if speeds else 0.0\n",
    "        avg_accel = float(np.mean(accels)) if accels else 0.0\n",
    "        fast_ratio = float(np.mean([s > Config.SPEED_THRESH_PX for s in speeds])) if speeds else 0.0\n",
    "        loiter_ratio = float(np.mean(loiter_flags)) if loiter_flags else 0.0\n",
    "        stationary_ratio = float(np.mean(stationary_flags)) if stationary_flags else 0.0\n",
    "\n",
    "        min_person_obj = 1e6\n",
    "        for p in people:\n",
    "            px, py = p[\"center\"]\n",
    "            for o in others:\n",
    "                ox, oy = o[\"center\"]\n",
    "                d = float(np.hypot(px - ox, py - oy))\n",
    "                if d < min_person_obj: min_person_obj = d\n",
    "        if not people or not others:\n",
    "            min_person_obj = 1e6\n",
    "\n",
    "        pair_dists = []\n",
    "        for i in range(len(people)):\n",
    "            p1 = people[i][\"center\"]\n",
    "            for j in range(i+1, len(people)):\n",
    "                p2 = people[j][\"center\"]\n",
    "                pair_dists.append(float(np.hypot(p1[0]-p2[0], p1[1]-p2[1])))\n",
    "        min_inter_person = float(np.min(pair_dists)) if pair_dists else 1e6\n",
    "        avg_inter_person = float(np.mean(pair_dists)) if pair_dists else 1e6\n",
    "\n",
    "        ages = []\n",
    "        for o in objs:\n",
    "            tid = o[\"id\"]\n",
    "            ages.append(self.frame_idx - self.first_seen.get(tid, self.frame_idx) + 1)\n",
    "        mean_age = float(np.mean(ages)) if ages else 0.0\n",
    "        med_age = float(np.median(ages)) if ages else 0.0\n",
    "        max_age = float(np.max(ages)) if ages else 0.0\n",
    "\n",
    "        p_confs = [c for cid, c in self.last_detections if cid == 0]\n",
    "        o_confs = [c for cid, c in self.last_detections if cid != 0]\n",
    "        p_conf_mean = float(np.mean(p_confs)) if p_confs else 0.0\n",
    "        p_conf_max = float(np.max(p_confs)) if p_confs else 0.0\n",
    "        o_conf_mean = float(np.mean(o_confs)) if o_confs else 0.0\n",
    "        o_conf_max = float(np.max(o_confs)) if o_confs else 0.0\n",
    "\n",
    "        grid = np.zeros((3,3), dtype=float)\n",
    "        if self.w > 0 and self.h > 0:\n",
    "            for p in people:\n",
    "                x, y = p[\"center\"]\n",
    "                gi = min(2, max(0, int((y / self.h) * 3)))\n",
    "                gj = min(2, max(0, int((x / self.w) * 3)))\n",
    "                grid[gi, gj] += 1.0\n",
    "        grid_mean, grid_max, grid_std = float(grid.mean()), float(grid.max()), float(grid.std())\n",
    "        diag = self.img_diag\n",
    "        return {\n",
    "            \"num_people\": float(num_people),\n",
    "            \"num_objects\": float(num_objects),\n",
    "            \"avg_speed_px\": avg_speed,\n",
    "            \"max_speed_px\": max_speed,\n",
    "            \"avg_accel_px\": avg_accel,\n",
    "            \"fast_ratio\": fast_ratio,\n",
    "            \"loiter_ratio\": loiter_ratio,\n",
    "            \"stationary_ratio\": stationary_ratio,\n",
    "            \"min_person_obj_px\": min_person_obj,\n",
    "            \"min_inter_person_px\": min_inter_person,\n",
    "            \"avg_inter_person_px\": avg_inter_person,\n",
    "            \"min_person_obj_norm\": min_person_obj/diag,\n",
    "            \"min_inter_person_norm\": min_inter_person/diag,\n",
    "            \"avg_inter_person_norm\": avg_inter_person/diag,\n",
    "            \"mean_track_age\": mean_age,\n",
    "            \"median_track_age\": med_age,\n",
    "            \"max_track_age\": max_age,\n",
    "            \"person_conf_mean\": p_conf_mean,\n",
    "            \"person_conf_max\": p_conf_max,\n",
    "            \"object_conf_mean\": o_conf_mean,\n",
    "            \"object_conf_max\": o_conf_max,\n",
    "            \"grid_mean\": grid_mean,\n",
    "            \"grid_max\": grid_max,\n",
    "            \"grid_std\": grid_std,\n",
    "        }\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.732071Z",
     "iopub.status.busy": "2025-08-24T17:05:46.731863Z",
     "iopub.status.idle": "2025-08-24T17:05:46.748040Z",
     "shell.execute_reply": "2025-08-24T17:05:46.747422Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.732047Z"
    }
   },
   "outputs": [],
   "source": [
    "class VideoProcessor:\n",
    "    def __init__(self, detector, tracker):\n",
    "        self.detector = detector\n",
    "        self.tracker = tracker\n",
    "\n",
    "    def process(self, video_path: Path, use_cache=True):\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            print(f\"ERROR: cannot open {video_path}\")\n",
    "            return [], {}\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        cached = read_cache(video_path) if use_cache else None\n",
    "        per_frame_dets = []\n",
    "        flogger = FeatureLogger(fps=fps, w=w, h=h)\n",
    "        frame_feats = []\n",
    "        idx = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            if cached is not None and idx < len(cached):\n",
    "                raw = cached[idx]\n",
    "                dets = [(float(d[\"box\"][0]), float(d[\"box\"][1]), float(d[\"box\"][2]), float(d[\"box\"][3]),\n",
    "                         float(d[\"conf\"]), int(d[\"cls\"])) for d in raw]\n",
    "                class_names = self.detector.names\n",
    "            else:\n",
    "                dets, class_names = self.detector.detect(frame)\n",
    "                per_frame_dets.append([{\"box\":[d[0],d[1],d[2],d[3]], \"conf\":d[4], \"cls\":d[5]} for d in dets])\n",
    "\n",
    "            flogger.set_last_detections(dets)\n",
    "            tracked = self.tracker.update(frame, dets, class_names)\n",
    "            feats = flogger.step(tracked)\n",
    "            frame_feats.append(feats)\n",
    "            idx += 1\n",
    "\n",
    "        cap.release()\n",
    "        if cached is None and use_cache:\n",
    "            write_cache(video_path, per_frame_dets)\n",
    "        return frame_feats, {\"fps\": fps, \"w\": w, \"h\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.748984Z",
     "iopub.status.busy": "2025-08-24T17:05:46.748761Z",
     "iopub.status.idle": "2025-08-24T17:05:46.766965Z",
     "shell.execute_reply": "2025-08-24T17:05:46.766137Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.748960Z"
    }
   },
   "outputs": [],
   "source": [
    "def collect_test_videos():\n",
    "    return sorted([p for p in Config.TEST_VIDEOS_PATH.iterdir() if p.suffix.lower() in [\".avi\", \".mp4\"]])\n",
    "\n",
    "def collect_train_videos():\n",
    "    p = Config.TRAIN_VIDEOS_PATH\n",
    "    if not p.exists(): return []\n",
    "    return sorted([p for p in p.iterdir() if p.suffix.lower() in [\".avi\", \".mp4\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.768138Z",
     "iopub.status.busy": "2025-08-24T17:05:46.767870Z",
     "iopub.status.idle": "2025-08-24T17:05:46.781234Z",
     "shell.execute_reply": "2025-08-24T17:05:46.780524Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.768116Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_val_hold(videos):\n",
    "    val, hold = [], []\n",
    "    for v in videos:\n",
    "        if (numeric_stem(v) % 2 == 0) == Config.VALIDATION_ON_EVEN:\n",
    "            val.append(v)\n",
    "        else:\n",
    "            hold.append(v)\n",
    "    return val, hold\n",
    "\n",
    "def build_feature_matrix(frame_feats):\n",
    "    X = np.asarray([[float(f[k]) for k in FEATURE_ORDER] for f in frame_feats], dtype=np.float32)\n",
    "    X[~np.isfinite(X)] = 0.0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.782229Z",
     "iopub.status.busy": "2025-08-24T17:05:46.782019Z",
     "iopub.status.idle": "2025-08-24T17:05:46.799957Z",
     "shell.execute_reply": "2025-08-24T17:05:46.799023Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.782205Z"
    }
   },
   "outputs": [],
   "source": [
    "def align_labels_length(labels, length):\n",
    "    y = np.zeros(length, dtype=int)\n",
    "    m = min(length, len(labels))\n",
    "    y[:m] = labels[:m]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.801080Z",
     "iopub.status.busy": "2025-08-24T17:05:46.800868Z",
     "iopub.status.idle": "2025-08-24T17:05:46.818129Z",
     "shell.execute_reply": "2025-08-24T17:05:46.817348Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.801064Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_with_labels(detector, tracker, videos):\n",
    "    vp = VideoProcessor(detector, tracker)\n",
    "    rows = []\n",
    "    for v in videos:\n",
    "        stem_for_label = normalize_stem_for_label(v.stem)\n",
    "        gt_path = Config.GROUND_TRUTH_FOLDER_PATH / f\"{stem_for_label}_label.mat\"\n",
    "        if not gt_path.exists():\n",
    "            print(f\"WARNING: expected GT missing: {gt_path.name} for {v.name}, skipping.\")\n",
    "            continue\n",
    "        gt = robust_load_gt(gt_path)\n",
    "        if gt is None or gt.size == 0:\n",
    "            print(f\"WARNING: empty/unknown GT schema for {gt_path.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        feats, _ = vp.process(v, use_cache=True)\n",
    "        if not feats:\n",
    "            print(f\"WARNING: no frames for {v.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        X = build_feature_matrix(feats)\n",
    "        y = align_labels_length(gt, len(X))\n",
    "        df = pd.DataFrame(X, columns=FEATURE_ORDER)\n",
    "        df[\"label\"] = y\n",
    "        df[\"video\"] = v.name\n",
    "        df[\"frame_idx\"] = np.arange(len(X))\n",
    "        rows.append(df)\n",
    "        print(f\"{v.name}: frames={len(X)} aligned={len(y)} (GT={len(gt)})\")\n",
    "    return pd.concat(rows, axis=0, ignore_index=True) if rows else pd.DataFrame()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.820584Z",
     "iopub.status.busy": "2025-08-24T17:05:46.819262Z",
     "iopub.status.idle": "2025-08-24T17:05:46.835544Z",
     "shell.execute_reply": "2025-08-24T17:05:46.834003Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.820557Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_no_labels(detector, tracker, videos):\n",
    "    vp = VideoProcessor(detector, tracker)\n",
    "    rows = []\n",
    "    for v in videos:\n",
    "        feats, _ = vp.process(v, use_cache=True)\n",
    "        if not feats:\n",
    "            print(f\"WARNING: no frames for {v.name}, skipping.\")\n",
    "            continue\n",
    "        X = build_feature_matrix(feats)\n",
    "        df = pd.DataFrame(X, columns=FEATURE_ORDER)\n",
    "        df[\"label\"] = 0\n",
    "        df[\"video\"] = v.name\n",
    "        df[\"frame_idx\"] = np.arange(len(X))\n",
    "        rows.append(df)\n",
    "        print(f\"{v.name}: frames={len(X)} (train negatives)\")\n",
    "    return pd.concat(rows, axis=0, ignore_index=True) if rows else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.837105Z",
     "iopub.status.busy": "2025-08-24T17:05:46.836857Z",
     "iopub.status.idle": "2025-08-24T17:05:46.851752Z",
     "shell.execute_reply": "2025-08-24T17:05:46.851119Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.837086Z"
    }
   },
   "outputs": [],
   "source": [
    "def downsample_negatives(df, ratio=Config.NEGATIVE_RATIO, seed=Config.RANDOM_SEED):\n",
    "    pos = df[df[\"label\"] == 1]\n",
    "    neg = df[df[\"label\"] == 0]\n",
    "    if len(pos) == 0 or len(neg) == 0:\n",
    "        return df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    max_neg = int(ratio * len(pos))\n",
    "    if len(neg) > max_neg:\n",
    "        neg = neg.sample(n=max_neg, random_state=seed)\n",
    "    out = pd.concat([pos, neg], axis=0, ignore_index=True)\n",
    "    return out.sample(frac=1.0, random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.852791Z",
     "iopub.status.busy": "2025-08-24T17:05:46.852587Z",
     "iopub.status.idle": "2025-08-24T17:05:46.865484Z",
     "shell.execute_reply": "2025-08-24T17:05:46.864803Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.852776Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_lgbm(X_train, y_train, X_val, y_val, seed=Config.RANDOM_SEED):\n",
    "    pos = max(1, int((y_train == 1).sum()))\n",
    "    neg = max(1, int((y_train == 0).sum()))\n",
    "    spw = neg / pos\n",
    "    clf = LGBMClassifier(\n",
    "        n_estimators=1500,\n",
    "        num_leaves=8,\n",
    "        max_depth=3,     \n",
    "        learning_rate=0.05,\n",
    "        min_data_in_leaf=8,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=0.5,\n",
    "        reg_alpha=0.0,\n",
    "        objective=\"binary\",\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=spw\n",
    "    )\n",
    "    clf.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[__import__(\"lightgbm\").early_stopping(100, first_metric_only=True, verbose=False)]\n",
    "    )\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.866441Z",
     "iopub.status.busy": "2025-08-24T17:05:46.866221Z",
     "iopub.status.idle": "2025-08-24T17:05:46.879450Z",
     "shell.execute_reply": "2025-08-24T17:05:46.878862Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.866422Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(clf, X, y_true, thr=0.5):\n",
    "    scores = clf.predict_proba(X)[:, 1]\n",
    "    y_pred = (scores >= thr).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, scores)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    return {\"precision\": float(p), \"recall\": float(r), \"f1\": float(f1), \"auc\": float(auc), \"scores\": scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.880463Z",
     "iopub.status.busy": "2025-08-24T17:05:46.880208Z",
     "iopub.status.idle": "2025-08-24T17:05:46.896413Z",
     "shell.execute_reply": "2025-08-24T17:05:46.895754Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.880446Z"
    }
   },
   "outputs": [],
   "source": [
    "def best_threshold(clf, X, y_true, steps=61):\n",
    "    scores = clf.predict_proba(X)[:, 1]\n",
    "    best = {\"thr\": 0.5, \"f1\": -1.0, \"precision\":0.0, \"recall\":0.0}\n",
    "    for t in np.linspace(0.05, 0.95, steps):\n",
    "        y_pred = (scores >= t).astype(int)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "        if f1 > best[\"f1\"]:\n",
    "            best = {\"thr\": float(t), \"f1\": float(f1), \"precision\": float(p), \"recall\": float(r)}\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:05:46.897459Z",
     "iopub.status.busy": "2025-08-24T17:05:46.897210Z",
     "iopub.status.idle": "2025-08-24T17:13:01.925570Z",
     "shell.execute_reply": "2025-08-24T17:13:01.924163Z",
     "shell.execute_reply.started": "2025-08-24T17:05:46.897433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "Models ready.\n",
      "Found 21 test videos; 16 training videos.\n",
      "Validation side: ['02.avi', '04.avi', '06.avi', '08.avi', '10.avi', '12.avi', '14.avi', '16.avi', '18.avi', '20.avi']\n",
      "Holdout side:    ['01.avi', '03.avi', '05.avi', '07.avi', '09.avi', '11.avi', '13.avi', '15.avi', '17.avi', '19.avi', '21.avi']\n",
      "Extracting labeled features from validation side (testing_videos)...\n",
      "02.avi: frames=1211 aligned=1211 (GT=1211)\n",
      "04.avi: frames=947 aligned=947 (GT=947)\n",
      "06.avi: frames=1283 aligned=1283 (GT=1283)\n",
      "08.avi: frames=36 aligned=36 (GT=36)\n",
      "10.avi: frames=841 aligned=841 (GT=841)\n",
      "12.avi: frames=1271 aligned=1271 (GT=1271)\n",
      "14.avi: frames=507 aligned=507 (GT=507)\n",
      "16.avi: frames=740 aligned=740 (GT=740)\n",
      "18.avi: frames=294 aligned=294 (GT=294)\n",
      "20.avi: frames=273 aligned=273 (GT=273)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading models...\")\n",
    "detector = Detector()\n",
    "tracker = Tracker()\n",
    "print(\"Models ready.\")\n",
    "test_videos = collect_test_videos()\n",
    "assert len(test_videos) > 0, \"No videos found in testing_videos/\"\n",
    "train_videos = collect_train_videos()\n",
    "print(f\"Found {len(test_videos)} test videos; {len(train_videos)} training videos.\")\n",
    "val_videos, hold_videos = split_val_hold(test_videos)\n",
    "print(\"Validation side:\", [v.name for v in val_videos])\n",
    "print(\"Holdout side:   \", [v.name for v in hold_videos])\n",
    "print(\"Extracting labeled features from validation side (testing_videos)...\")\n",
    "df_val = extract_features_with_labels(detector, tracker, val_videos)\n",
    "assert not df_val.empty, \"No validation data assembled.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:13:01.928164Z",
     "iopub.status.busy": "2025-08-24T17:13:01.926412Z",
     "iopub.status.idle": "2025-08-24T17:29:20.643636Z",
     "shell.execute_reply": "2025-08-24T17:29:20.641980Z",
     "shell.execute_reply.started": "2025-08-24T17:13:01.928138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting negatives from training_videos...\n",
      "01.avi: frames=1364 (train negatives)\n",
      "02.avi: frames=1511 (train negatives)\n",
      "03.avi: frames=1487 (train negatives)\n",
      "04.avi: frames=1511 (train negatives)\n",
      "05.avi: frames=815 (train negatives)\n",
      "06.avi: frames=1511 (train negatives)\n",
      "07.avi: frames=1099 (train negatives)\n",
      "08.avi: frames=1017 (train negatives)\n",
      "09.avi: frames=1391 (train negatives)\n",
      "10.avi: frames=1223 (train negatives)\n",
      "11.avi: frames=781 (train negatives)\n",
      "12.avi: frames=145 (train negatives)\n",
      "13.avi: frames=366 (train negatives)\n",
      "14.avi: frames=510 (train negatives)\n",
      "15.avi: frames=353 (train negatives)\n",
      "16.avi: frames=244 (train negatives)\n",
      "Training frames after downsampling: P=18, N=180\n"
     ]
    }
   ],
   "source": [
    "if Config.USE_TRAIN_NEGATIVES and len(train_videos) > 0:\n",
    "    print(\"Extracting negatives from training_videos...\")\n",
    "    df_train_neg = extract_features_no_labels(detector, tracker, train_videos)\n",
    "else:\n",
    "    df_train_neg = pd.DataFrame()\n",
    "if not df_train_neg.empty:\n",
    "    df_train_pool = pd.concat([df_val, df_train_neg], axis=0, ignore_index=True)\n",
    "    df_train_bal = downsample_negatives(df_train_pool, ratio=Config.NEGATIVE_RATIO)\n",
    "    X_train = df_train_bal[FEATURE_ORDER].to_numpy(np.float32)\n",
    "    y_train = df_train_bal[\"label\"].to_numpy(int)\n",
    "    nval = min(Config.VAL_SLICE_MAX, len(df_val))\n",
    "    X_val_int = df_val[FEATURE_ORDER].to_numpy(np.float32)[-nval:]\n",
    "    y_val_int = df_val[\"label\"].to_numpy(int)[-nval:]\n",
    "    print(f\"Training frames after downsampling: P={int((y_train==1).sum())}, N={int((y_train==0).sum())}\")\n",
    "else:\n",
    "    Xv = df_val[FEATURE_ORDER].to_numpy(np.float32); yv = df_val[\"label\"].to_numpy(int)\n",
    "    split = int(0.8 * len(df_val))\n",
    "    X_train, y_train = Xv[:split], yv[:split]\n",
    "    X_val_int, y_val_int = Xv[split:], yv[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:29:20.649617Z",
     "iopub.status.busy": "2025-08-24T17:29:20.649332Z",
     "iopub.status.idle": "2025-08-24T17:29:21.090286Z",
     "shell.execute_reply": "2025-08-24T17:29:21.089693Z",
     "shell.execute_reply.started": "2025-08-24T17:29:20.649597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Info] Number of positive: 18, number of negative: 180\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 198, number of used features: 24\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.090909 -> initscore=-2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "Validation sweep: F1=0.9000 at thr=0.95 (P=0.818, R=1.000)\n"
     ]
    }
   ],
   "source": [
    "clf = train_lgbm(X_train, y_train, X_val_int, y_val_int)\n",
    "best = best_threshold(clf, df_val[FEATURE_ORDER].to_numpy(np.float32), df_val[\"label\"].to_numpy(int))\n",
    "print(f\"Validation sweep: F1={best['f1']:.4f} at thr={best['thr']:.2f} (P={best['precision']:.3f}, R={best['recall']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T17:29:21.091467Z",
     "iopub.status.busy": "2025-08-24T17:29:21.091170Z",
     "iopub.status.idle": "2025-08-24T17:37:10.290626Z",
     "shell.execute_reply": "2025-08-24T17:37:10.289990Z",
     "shell.execute_reply.started": "2025-08-24T17:29:21.091440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting labeled features from holdout side...\n",
      "01.avi: frames=1439 aligned=1439 (GT=1439)\n",
      "03.avi: frames=923 aligned=923 (GT=923)\n",
      "05.avi: frames=1007 aligned=1007 (GT=1007)\n",
      "07.avi: frames=605 aligned=605 (GT=605)\n",
      "09.avi: frames=1175 aligned=1175 (GT=1175)\n",
      "11.avi: frames=472 aligned=472 (GT=472)\n",
      "13.avi: frames=549 aligned=549 (GT=549)\n",
      "15.avi: frames=1001 aligned=1001 (GT=1001)\n",
      "17.avi: frames=426 aligned=426 (GT=426)\n",
      "19.avi: frames=248 aligned=248 (GT=248)\n",
      "21.avi: frames=76 aligned=76 (GT=76)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "\n",
      "=== FINAL (Holdout) ===\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1:        0.0000\n",
      "ROC-AUC:   0.8702\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting labeled features from holdout side...\")\n",
    "df_hold = extract_features_with_labels(detector, tracker, hold_videos)\n",
    "if df_hold.empty:\n",
    "    print(\"No holdout data available; skipping final metrics.\")\n",
    "    eval_hold = None\n",
    "else:\n",
    "    X_hold = df_hold[FEATURE_ORDER].to_numpy(np.float32)\n",
    "    y_hold = df_hold[\"label\"].to_numpy(int)\n",
    "    eval_hold = evaluate(clf, X_hold, y_hold, thr=best[\"thr\"])\n",
    "    print(\"\\n=== FINAL (Holdout) ===\")\n",
    "    print(f\"Precision: {eval_hold['precision']:.4f}\")\n",
    "    print(f\"Recall:    {eval_hold['recall']:.4f}\")\n",
    "    print(f\"F1:        {eval_hold['f1']:.4f}\")\n",
    "    print(f\"ROC-AUC:   {eval_hold['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:01:49.722202Z",
     "iopub.status.busy": "2025-08-24T18:01:49.721693Z",
     "iopub.status.idle": "2025-08-24T18:01:49.728651Z",
     "shell.execute_reply": "2025-08-24T18:01:49.727811Z",
     "shell.execute_reply.started": "2025-08-24T18:01:49.722177Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def sweep_thresholds(y_true, y_prob, steps=201):\n",
    "    ts = np.linspace(0.0, 1.0, steps)\n",
    "    out = []\n",
    "    for t in ts:\n",
    "        y_pred = (y_prob >= t).astype(int)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "        out.append((float(t), float(p), float(r), float(f1)))\n",
    "    return np.array(out)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def pick_threshold(curve, metric=\"f1\"):\n",
    "    idx = {\"precision\": 1, \"recall\": 2, \"f1\": 3}[metric]\n",
    "    best_row = curve[np.argmax(curve[:, idx])]\n",
    "    best_t, best_p, best_r, best_f1 = best_row\n",
    "    return {\"thr\": best_t, \"precision\": best_p, \"recall\": best_r, \"f1\": best_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:01:49.730447Z",
     "iopub.status.busy": "2025-08-24T18:01:49.729810Z",
     "iopub.status.idle": "2025-08-24T18:01:57.090368Z",
     "shell.execute_reply": "2025-08-24T18:01:57.089737Z",
     "shell.execute_reply.started": "2025-08-24T18:01:49.730421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "Best F1=0.900 at thr=0.9435 (P=0.818, R=1.000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_val_true = df_val[\"label\"].to_numpy(np.int32)\n",
    "y_val_prob = clf.predict_proba(df_val[FEATURE_ORDER].to_numpy(np.float32))[:, 1]\n",
    "curve = sweep_thresholds(y_val_true, y_val_prob, steps=2001) # finer grid (0.0005 step)\n",
    "best = pick_threshold(curve, metric=\"f1\")\n",
    "print(f\"Best F1={best['f1']:.3f} at thr={best['thr']:.4f} (P={best['precision']:.3f}, R={best['recall']:.3f})\")\n",
    "best_thr=best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:01:57.091693Z",
     "iopub.status.busy": "2025-08-24T18:01:57.091435Z",
     "iopub.status.idle": "2025-08-24T18:01:57.105817Z",
     "shell.execute_reply": "2025-08-24T18:01:57.105026Z",
     "shell.execute_reply.started": "2025-08-24T18:01:57.091661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n"
     ]
    }
   ],
   "source": [
    "eval_hold = None\n",
    "if df_hold is not None and not df_hold.empty:\n",
    "    y_hold_true = df_hold[\"label\"].to_numpy(np.int32)\n",
    "    y_hold_prob = clf.predict_proba(df_hold[FEATURE_ORDER].to_numpy(np.float32))[:, 1]\n",
    "    y_hold_pred = (y_hold_prob >= best['thr']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:01:57.106455Z",
     "iopub.status.busy": "2025-08-24T18:01:57.106252Z",
     "iopub.status.idle": "2025-08-24T18:01:57.131137Z",
     "shell.execute_reply": "2025-08-24T18:01:57.130570Z",
     "shell.execute_reply.started": "2025-08-24T18:01:57.106439Z"
    }
   },
   "outputs": [],
   "source": [
    "out_dir = Config.ARTIFACT_DIR\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(clf, out_dir / \"lgbm_frame_scorer.joblib\")\n",
    "\n",
    "meta = {\n",
    "    \"model_type\": \"lightgbm\",\n",
    "    \"threshold\": float(0.9435), \n",
    "    \"feature_order\": list(FEATURE_ORDER),\n",
    "    \"val_videos\": [v.name for v in val_videos],\n",
    "    \"holdout_videos\": [v.name for v in hold_videos],\n",
    "    \"best_iteration\": int(getattr(clf, \"best_iteration_\", getattr(clf, \"n_estimators\", 0))),\n",
    "    \"negative_ratio\": float(Config.NEGATIVE_RATIO),\n",
    "    \"validation_operating_point\": {\n",
    "        \"precision\": 0.818,\n",
    "        \"recall\": 1.000,\n",
    "        \"f1\": 0.900,\n",
    "        \"threshold\": 0.9435\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T18:01:57.132195Z",
     "iopub.status.busy": "2025-08-24T18:01:57.132028Z",
     "iopub.status.idle": "2025-08-24T18:01:57.536180Z",
     "shell.execute_reply": "2025-08-24T18:01:57.535407Z",
     "shell.execute_reply.started": "2025-08-24T18:01:57.132180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "\n",
      "Artifacts written to /kaggle/working/artifacts_train\n"
     ]
    }
   ],
   "source": [
    "if eval_hold is not None:\n",
    "    meta[\"final_holdout\"] = {k: float(eval_hold[k]) for k in [\"precision\",\"recall\",\"f1\",\"auc\"]}\n",
    "\n",
    "with open(out_dir / \"meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "val_scores = y_val_prob\n",
    "df_val_out = df_val.copy()\n",
    "df_val_out[\"score\"] = val_scores\n",
    "df_val_out.to_csv(out_dir / \"validation_frames.csv\", index=False)\n",
    "\n",
    "if df_hold is not None and not df_hold.empty:\n",
    "    hold_scores = clf.predict_proba(df_hold[FEATURE_ORDER].to_numpy(np.float32))[:, 1]\n",
    "    df_hold_out = df_hold.copy()\n",
    "    df_hold_out[\"score\"] = hold_scores\n",
    "    df_hold_out.to_csv(out_dir / \"holdout_frames.csv\", index=False)\n",
    "\n",
    "print(f\"\\nArtifacts written to {out_dir.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8126597,
     "sourceId": 12848619,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
